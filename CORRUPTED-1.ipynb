{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Load your dataset\n",
    "dataset = load_dataset('cairocode/MSP_POD_SYL')  # Replace with your actual dataset name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPEG support: False\n",
      "PNG support: False\n",
      "WebP support: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_102547/2526314912.py:3: UserWarning: Unknown feature 'jpeg'.\n",
      "  print(\"JPEG support:\", features.check(\"jpeg\"))\n",
      "/tmp/ipykernel_102547/2526314912.py:4: UserWarning: Unknown feature 'png'.\n",
      "  print(\"PNG support:\", features.check(\"png\"))\n"
     ]
    }
   ],
   "source": [
    "from PIL import features\n",
    "\n",
    "print(\"JPEG support:\", features.check(\"jpeg\"))\n",
    "print(\"PNG support:\", features.check(\"png\"))\n",
    "print(\"WebP support:\", features.check(\"webp\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_data = dataset.filter(lambda x: x['speaker'] != 'Unknown')['train']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = int(len(remaining_data)*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'speaker'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Group the data by class\n",
    "class_groups = defaultdict(list)\n",
    "for idx, item in enumerate(remaining_data):\n",
    "    class_groups[item[column]].append(idx)\n",
    "\n",
    "# Ensure at least one sample from each class in validation set\n",
    "validation_indices = []\n",
    "train_indices = []\n",
    "\n",
    "for class_indices in class_groups.values():\n",
    "    if len(class_indices) > 1:\n",
    "        validation_indices.append(class_indices.pop(0))\n",
    "    train_indices.extend(class_indices)\n",
    "\n",
    "# Calculate remaining validation size\n",
    "remaining_val_size = val_size - len(validation_indices)\n",
    "\n",
    "# Randomly sample the rest of the validation set\n",
    "import random\n",
    "random.seed(42)\n",
    "additional_val_indices = random.sample(train_indices, remaining_val_size)\n",
    "\n",
    "validation_indices.extend(additional_val_indices)\n",
    "train_indices = [idx for idx in train_indices if idx not in additional_val_indices]\n",
    "\n",
    "# Create the datasets\n",
    "validation_dataset = remaining_data.select(validation_indices)\n",
    "train_dataset = remaining_data.select(train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'speaker'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = train_dataset[column]\n",
    "def adjust_speaker_ids(example, min_val):\n",
    "    example[column] = int(example[column]) - min_val\n",
    "    return example\n",
    "    \n",
    "unique_labels = list(set(S))\n",
    "\n",
    "min_val = min(int(label) for label in unique_labels)  # If the labels are strings representing integers\n",
    "Cval = len(unique_labels)\n",
    "\n",
    "train_dataset = train_dataset.map(lambda example: adjust_speaker_ids(example, min_val))\n",
    "\n",
    "\n",
    "validation_dataset = validation_dataset.map(lambda example: adjust_speaker_ids(example, min_val))\n",
    "S = train_dataset[column]\n",
    "unique_labels = list(set(S))\n",
    "\n",
    "\n",
    "speaktonum = {label: str(index) for index, label in enumerate(unique_labels)}\n",
    "# Create a dictionary that maps numbers to labels\n",
    "numtospeak = {str(index): label for index, label in enumerate(unique_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dataset.filter(lambda x: x['speaker'] == 'Unknown')['train']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import Value\n",
    "\n",
    "def convert_speaker(value):\n",
    "    if value == 'Unknown':\n",
    "        return None\n",
    "    try:\n",
    "        return int(value)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# Convert the 'speaker' column\n",
    "test_dataset = test_dataset.map(\n",
    "    lambda x: {'speaker': convert_speaker(x['speaker'])},\n",
    "    remove_columns=['speaker']\n",
    ")\n",
    "\n",
    "# Set the column type to Int64\n",
    "test_dataset = test_dataset.cast_column('speaker', Value('int64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "train_d1 = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_d1.push_to_hub(\"cairocode/MSP_Pod_SYL4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets, DatasetDict\n",
    "\n",
    "\n",
    "train_dataset = load_dataset('cairocode/MSP_POD_OLD_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'EmoClass'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_files = []\n",
    "try:\n",
    "    for idx, sample in enumerate(train_data):\n",
    "        try:\n",
    "            label = sample[column]\n",
    "            img = sample['image']\n",
    "        except OSError as e:\n",
    "            print(f\"Error in sample {idx}: {e}\")\n",
    "            corrupted_files.append(idx)\n",
    "except OSError as e:\n",
    "    print(f\"Error in sample {idx}: {e}\")\n",
    "    corrupted_files.append(idx+1)\n",
    "\n",
    "print(f\"Corrupted files indices: {corrupted_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import tqdm\n",
    "\n",
    "for idx in tqdm.trange(len(train_data)):\n",
    "    try:\n",
    "        _ = train_data[idx][\"image\"].load()\n",
    "    except PIL.UnidentifiedImageError as e:\n",
    "        print(f\"Corrupted image at index={idx}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# corrupted_files[0] = corrupted_files[0] - 1\n",
    "corrupted_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if corrupted_files:\n",
    "    train_dataset_new = train_data.select([i for i in range(len(train_data)) if i not in corrupted_files])\n",
    "    print(f\"Removed {len(corrupted_files)} corrupted files from the dataset.\")\n",
    "else:\n",
    "    print(\"No corrupted files found.\")\n",
    "\n",
    "train_data = train_dataset_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "train_d1 = DatasetDict({\n",
    "    'train': train_dataset_new,\n",
    "    # 'validation': train_dataset['validation'],\n",
    "    # 'test': train_dataset['test']\n",
    "})\n",
    "\n",
    "train_d1.push_to_hub(\"MSP_POD_OLD_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to try opening an image\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "def try_open_image(image_data):\n",
    "    try:\n",
    "        if isinstance(image_data, dict) and 'bytes' in image_data:\n",
    "            # If it's a dict with 'bytes' key, use that\n",
    "            image_data = image_data['bytes']\n",
    "        \n",
    "        if isinstance(image_data, bytes):\n",
    "            # If it's bytes, try to convert to numpy array and then to PIL Image\n",
    "            nparr = np.frombuffer(image_data, np.uint8)\n",
    "            img = Image.fromarray(nparr)\n",
    "        elif isinstance(image_data, np.ndarray):\n",
    "            # If it's already a numpy array, convert to PIL Image\n",
    "            img = Image.fromarray(image_data)\n",
    "        elif isinstance(image_data, Image.Image):\n",
    "            # If it's already a PIL Image, use it directly\n",
    "            img = image_data\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected image data type: {type(image_data)}\")\n",
    "        \n",
    "        # Try to convert to RGB to ensure it's a valid image\n",
    "        img.convert('RGB')\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# List to store indices of valid examples\n",
    "valid_indices = []\n",
    "\n",
    "# Loop through the dataset\n",
    "for idx, example in enumerate(dataset):\n",
    "    # Assuming the image is stored in a column named 'image'\n",
    "    # Adjust this if your image column has a different name\n",
    "    result = try_open_image(example['image'])\n",
    "    \n",
    "    if result is True:\n",
    "        valid_indices.append(idx)\n",
    "    else:\n",
    "        print(f\"Issue with image at index {idx}: {result}\")\n",
    "\n",
    "# Create a new dataset with only the valid examples\n",
    "cleaned_dataset = dataset.select(valid_indices)\n",
    "\n",
    "print(f\"Original dataset size: {len(dataset)}\")\n",
    "print(f\"Cleaned dataset size: {len(cleaned_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_dataset\n",
    "dataset -= load_dataset('\\')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
